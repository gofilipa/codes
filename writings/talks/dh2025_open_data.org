* draft
** sketch
Provocation:
- LLMs are expressive language machines: Their outputs depend on their
  inputs.
- "Open" has to change - has to be tied more firmly to the commons.

The problem is that definitions of what counts as "open" hinge on
misunderstandings and ignorance about how LLMs work, and is being used
to defend all kinds of theft.

Foundation models, which are trained on close to everything, should be
100 percent open source. The tech is based on machine learning
algorithms that have no copyright, and data is on everything.
Fine-tuning is what should be proprietary, if at all. 

Vectors reflect their training data.

** outline
The meaning of "open" changes with big data methods. What was open for
Lawrence Lessig in early 2000s cannot be "open" for us.
- will show three examples of how "open" is being operationalized. 

The problem: industry defines "open" as "open for business"
- definition is based on a mischaracterizations of what kind of thing
  LLMs are and what they do to language.

Example 1:
- in the public discourse, operationalizing the word "freedom" for
  commercial purposes.
  
Example 2:
- in the legal discourse, adopting "non-expressive" and
  "transformative" status on LLM data (vectors).

My argument:
- Vectors are expressive, reflect the training data, contain traces of
  the data they are trained on.

Example 3:
- Examples from heritage project, perhaps contrasted with another data
  source?
- Queen = King - Man + Woman
  - acting as if there an ideal vector for "queen", like a vector is a
    definition.
  - but vectors are encodings; not objective definitions; they are
    traces of the data they are trained on. 

Solutions:
- Licensing has to change, and is changing. Indigenous groups are
  leading the way here.
- Training has to change. EleutherAI creating Pile V2. 

** move to draft
The concept of "open" relies on commercialization, fear mongering,
single perspective. 
- "freedom to learn"
- unfettered vs fair use

  

What has been "fair use"
- databases, search results "transformative"
- without affecting marketability

How OpenAI defines "open":
- the name itself, the original mission, share code and patents with
  the world.
- more recently, open aligned with "freedom to learn"
  - anthropomophizing machine learning.
  - "freedom of intelligence" -- "freedom to access and benefit" 
- associated with innovation
  - monopolizing practices (Big Tech prominence)
  - "innovation & adoption" (congressional hearing may 8)
  - Telecommunications Act 1996: deregulated internet for
    consolidation of telecommunications companies.
- positioned against authoritarianism and communism.
  - "the ai race" is manufacutred
  - irony: DeepSeek is open source
  - unfettered vs fair use - depends on perspective

What we can do, new licenses to reflect the moment.

We need new licenses to protect our data. And smaller projects.
Building off their foundation models to make something smaller.
Innovate. Like DeepSeek.

"Non-expressive use" - what happens when language is distilled into a
statistical measure? Is this non-expressive?

The arguments that statistics of language are facts, not expression,
and therefore can be extracted and monetized -- this is what we have
to push against.

A vector is its own expression, that is subject to protection. 

** draft
This presentation is about the concept of "open source" is changing in
light of big data methods associated with machine learning.

"Open" in a technical sense means something different today that it
did at the emergence of Open Source and open data. The use of such
data was not automated, so being "open" didn't have the same effect.
Now that we have methods for vaccuuming up that data at scale, and
creating products that compete with the original data, we need to
rethink "open."

*** public & legal discourse around what is open
OpenAI, on how it presents itself around "open".

    SLIDE OAI's original mission

OpenAI's original mission, from its release in 2018, declared the
company's "goal is to advance digital intelligence in the way that is
most likely to benefit humanity as a whole, unconstrained by a need to
generate financial return." It claimed that AI should be "as broadly
and evenly distributed as possible," and that its code, research and
patents, "will be shared with the world" (12/11/2018 press release).

More recently, this language has shifted from sharing to freedom.

    SLIDE OIA freedom-focused policy proposals

In a proposal to the OSTP from march of this year, the company makes a
series of "freedom-focused policy proposals" which are apparently
based on democracic values.

This proposal lists a litany of freedoms, including the "freedom of
intelligence", "freedom to access and benefit", "freedom to innovate,"
"freedom to learn." The last one, "freedom to learn" concerns
copyright.

#+begin_quote
We propose a copyright strategy that would extend the system’s role
into the Intelligence Age by protecting the rights and interests of
content creators while also protecting America’s AI leadership and
national security. The federal government can both secure Americans’
freedom to learn from AI, and avoid forfeiting our AI lead to the PRC
by preserving American AI models’ ability to learn from copyrighted
material.
#+end_quote

Here, interestingly, there are two learners: humans and AI. Not only
are the humans learning from AI, but the AI themselves are learning,
by taking copyrighted data as resources for "training."

Of course, in a discourse that already anthropomorphizes machine
learning tools as "intelligent", they are doing the same with
"learning". But "learning" for a machine is much different than a
human, leading to accelerated capacities not only in processing but
also in generating that a human cannot replicate.

But, the real justification for taking copyrighted data is buried in
the text here: a reference to competition with the "PRC", the Peoples'
Republic of China.

    SLIDE OAI proposal text 

In the proposal text, we see this justification spelled out in more
detail. This is in a section entitled, "Copyright: Promoting the
Freedom to Learn",

#+begin_quote
Applying the fair use doctrine to AI is not only a matter of American
competitiveness-—it’s a matter of national security. The rapid
advances seen with the PRC’s DeepSeek, among other recent
developments, show that America’s lead on frontier AI is far from
guaranteed. Given concerted state support for critical industries and
infrastructure projects, there’s little doubt that the PRC’s AI
developers will enjoy unfettered access to data—-including copyrighted
data—-that will improve their models. If the PRC’s developers have
unfettered access to data and American companies are left without fair
use access, the race for AI is effectively over. America loses, as
does the success of democratic AI. ("Proposal to OSTP")
#+end_quote

The context is DeepSeek, which was released by China in early 2025,
and accomplished impressive performance using a fraction of the
resources used by big tech companies in the US.

Here the bias emerges in the adjectives they use to describe data
collection: for China, it is "unfettered access", for the USA, it is
"fair use access". There is no difference between "unfettered" and
"fair use," because OpenAI (and other big tech companies) are not
limiting themselves in how they gather data.

They state,

#+begin_quote
our AI model training aligns with the core objectives of copyright and
the fair use doctrine, using existing works to create something wholly
new and different without eroding the commercial value of those
existing works. ("Proposal to OSTP")
#+end_quote

The fair use hinges on this notion of "creating something wholly new
and different". This is a reference to one of the legal criteria for
"fair use," which is called the "transformative".

How they are operationalizing the "transformative" criterion is fully
spelled out in another document, also in response to a US government
request for information.

    SLIDE OPENAI COMMENTS ON IP, quote campbell acuff-rose

To the United States Patent and Trademark Office, entitled, "Regarding
Request for Comments on Intellectual Property Protection for
Artificial Intelligence Innovation", OpenAI mounts their defence of
"fair use." This defense hinges on the status of AI technology as what
they call "highly transformative."

#+begin_quote
Although such transformative use is not absolutely necessary for a
finding of fair use, the goal of copyright, to promote science and the
arts, is generally furthered by the creation of transformative works.
Such works thus lie at the heart of the fair use doctrine's guarantee
of breathing space within the confines of copyright, and the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use. (/Campbell v. Acuff-Rose Music/ 1994)
#+end_quote

Here, they citing a passage from a court case that defends parody
(Campbell v. Acuff-Rose Music) as fair use. In that case, which was
argued at the Supreme Court in 1994, the ruling states that "the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use."

Building on this, OpenAI focus the majority of their argument on the
transformative nature of AI systems.

Before going into that argumentation, I will point out what they do
say about commercialization, and specifically, how content creators
ought to be compensated. This is a point that is slightly buried in
the document, in a footnote in a later section. In this section, they
argue that concerns about compensation, what they call "distributive
claims", are outside the responsibility of big tech companies. They
argue, for example, that:

#+begin_quote
"... this concern falls into a broader category of concerns about the
relationship between automation, labor, and economic growth"

"... we believe that such distributive claims are most efficiently
addressed through taxation and redistribution, rather than copyright
policy."
#+end_quote

After this sentence, they refer to a footnote, which contains a single
citation to a legal paper from 1994, entitled, "Why the Legal System
Is Less Efficient than the Income Tax in Redistributing Income."

    SLIDE WHY THE LEGAL SYSTEM... paper screenshot

This paper, which compares legal system versus the income tax system
as a means for distributing wealth, finds that the income tax system
is more efficient due to ability to apply formulas universally. The
footnote provides a single quote from the paper, that
"[R]edistribution through legal rules offers no advantage over
redistributions through the income tax system and is typically less
efficient." Besides this quote, it offers no additional information
about how such redistribution would work, if everyone would be taxed,
or just AI companies (somehow doubtful), and if everyone would receive
payments (As Sam Altman has discussed the potential for UBI or
"Universal Basic Income"), or, whether payments would go only to
content creators. My guess is that taxes would increase for everyone
in order to support content creators.

Moving back to copyright, and to the so-called "highly transformative"
nature of AI systems, I will now consider OpenAI's specific arguments
regarding this criterion.

First, they cite two legal cases, Authors Guild v. Google, 2015, and
Authors Guild v. HathiTrust, 2014, that set a precendence for thinking
about the "transformative" as a factor that intersects interestingly
with technological contexts. Both cases were brought by the Authors
Guild, a professional organization for writers in the US, to argue
that search results violate copyright. At the time, both Google and
Hathitrust had digitazed thousands to millions (in the case of Google)
of copyrighted books into a database for searching, and users could
see excerpts and other information about the copyrighted works on the
Google and Hathitrust search engines.

The ruling for both cases assert that search results constitute
something distinct from the original, which is fundamentally
transformative, that is, /information about books/. Such information
does not offer a replacement or substitute for the book, but rather,
it offers a new kind of object. Here, the importance is the
transformation of language from its original context, in a sentence or
on a page, to a represenation that is statistical in nature,
representing part of an aggregation. As the judge in the Hathitrust
case points out, "the result of a word search is different in purpose,
character, expression, meaning, and message from the page (and the
book) from which it is drawn" (/Author's Guild v. Hathitrust/, 97).
These court cases, significantly for databases and search engines, set
activities related to quantitative analysis, like text mining, as a
permissable use.

OpenAI take this concept of the "transformative" and applies it in
full force to their large language models.

They argue, essentially, that llms create a new kind of object based
on "patterns" of language use in the training data. They explain that,
#+begin_quote
"AI systems go well beyond preserving the content of individual works
by learning patterns in their whole training corpus and then using
those patterns to generate entirely novel media"
#+end_quote
They continue, explaining that,
#+begin_quote
"by learning patterns from its training corpus, an AI system can
eventually generate media that shares some commonalities with works in
the corpus (in the same way that English sentences share some
commonalities with each other by sharing a common grammar and
vocabulary) but cannot be found in it." ("Comment", 9-10)
#+end_quote
What they refer to as patterns are statistical representations of
language, a numerical representation that encodes a words semantic
meaning to the langauge model.

Basically, inside every language model, exists a kind of dictionary.
This dictionary consists of individual words (every single word that
is present in the training corpus), and each word is appended not by a
definition in human language, but by a definition in computer
language, with numbers. These numbers which append each word,
represent probabilities between that word and /every single other word
in the corpus/. They are long, very long (and this is why language
models are caled "large") lists of probabilities. So, inside the
language model, each word is defined not by what it represents in
itself, but by its relation to every other word in the corpus.

/For example, the word "cat" will have a series of numbers that
closely resembles the series of numbers that append the word,
"kitten," and not as close to the numbers that represent "dog." Still,
the numbers for "cat" and "dog" will be much closer to each other than
the numbers that represent "flower," for example./

Here is an example of the famous formula that introduced the concept
of the long list of numbers, known technically as "word vectors" to
the world.

#+begin_quote
King - Man + Woman = Queen

Mikolov et al., "Distributed Representations of Words and Phrases and
their Compositionality", 2013.
#+end_quote

I always like to show this formula, because it illustrates exactly the
reason why we need more humanists (or more humanist training) involved
in engineering and computer science research.

The formula showcases power of word vectors: that they can be used
determine word meaning through calculations. In other words, if every
word is transformed into a numerical representation, we can do math
with language. We start with the vector for the word "King," that is,
a numerical representation of what "King" means in relation to every
other word. If, from the vector of "King," we subtract the vector of
"Man," and add that of "Woman," we will arrive at the vector for the
word "Queen."

Nevermind that the formula relies on gender role and identity as
symmetrically opposed and universally true, the idea is that word
meaning can be reliably computed.

And this is why, OpenAI argue, their product is "highly
transformative," because it turns words into numerical forms that
represent meaning as a kind of statistic.

But the thing that they do not mention, which they perhaps do not want to
admit, is that vectors are far from generalizations of language as a
fact of idea-- rather, vectors are specifically tied to the data on
which they were trained.

To demonstrate, I'm going to show a few examples of ML-generated text
based on two very different data sources.









"synthesize similar data which yield increasingly compelling novel
media"

"nobody looking to read a specific webpage contained in the corpus
used to train an AI system can do so by studying the AI system or its
outputs"


"does copyright law’s protection of an author’s original expression
impede AI systems from generating insights about that expression?"
("Comments" 3).


- characterize vectors as "facts", statistical patterns,
  "non-expressive".



*** bank

Big Tech developers who are currently taking openly accessible data
(which is still protected under copyright), as the training material
for their latest language models. It will consider the legal cases
pending against Microsoft in particular, and consider some of the
policy proposals that OpenAI, their subsidiary, has made to the US
government, for what they call "democratic AI".

I started doing this research because I wanted to understand how they
justified taking massive amounts of data, without compensating content
creators, and privatizing the outputs of that data, without taking
responsibility for how those outputs affect the livelihoods of content
creators. What I found is that the justification relies on an argument
for freedom, which, perhaps unsurprisingly, relies on a claim a threat
to the country. Here, the emphasis comes from contrasting the US with
China. I close with some suggestions for building "open" work within
these constraints.

So I begin.


Before I go into current perspectives on the meaning of "open", will
discuss "fair use," which is a crucial concept for understanding how
even sources that are technically closed, or protected by copyright,
can be "open" under certain conditions.

"Fair use," as I'm sure many of you know, protects certain usages of
copyrighted data according to specific conditions, which have to do
with how much data is taken, how much it is altered, the use of the
data (such as educational or commercial), and how the use affects
marketability of the original. Historically, this has protected uses
like quoting sentences from a book, or making a copy for educational
or research purposes purposes, or creating a parody. A parody, for
example, is considered "highly transformative", that in no way can
substitute for the original.

Legality considers a balance between transformative status and
commercial effects. With the rise of the internet in the 90s and early
2000s, new lawsuits started appearing about whether search engines
counted as fair use. The rulings generally agreed that search engines
are fair use because they make "highly transformative" use of the
data, and only provide partial access to that data in the search
results. In /Author's Guild vs Google/ from 2015, a judged ruled that:
#+begin_quote
Google’s making of a digital copy to provide a search function is a
transformative use, which augments public knowledge by making
available information about Plaintiffs’ books without providing the
public with a substantial substitute (/Author's Guild vs Google,
2015/, 4).
#+end_quote
A major, perhaps the most substantial, concern in determining fair use
cases is whether the final product competes with or affects the
commercial value in any way of the original. And this makes sense,
because copyright, after all, exists precisely to protect content
creators.

As you might imagine, this is a perspective wholly neglected by tech
companies who violate copyright to train their machine learning
models.

Companies like "OpenAI", which have both "open" and "ai" in the name,
are misleading. They are not "open" (offering closed, proprietary
models) and they are not "ai" (but rather generators based on
statistical predications).







** close reading
I used a series of prompts to 

*** gpt2
#+begin_quote
We don't have to be a man, we don't have to be a woman, we are all
capable of being masculine.

#+end_quote

*** aclu
#+begin_quote


#+end_quote

*** heritage foundation

#+begin_quote


#+end_quote
** reading notes
*** Chandrasekhar 2025
- how do copyleft licenses transfer to datasets, models, tokens?
- EleutherAI developing the Pile V2
- Problem isn't that data is used without compensation, but that
  products/outcomes are not contributed back to the commons (19).
- are parameter's "transformative"?
- The issue becomes: who has the ability to create? To use the GPUs.
- alternative licenses:
  - Nwulite Odobo "dual regime" - free for users in developing
    countries, multiple licensors for a dataset
  - Kaitiakitanga - royalties go to community, community ownership
- language is extractive, indigenous communities know this. 
*** The Author’s Guild v. Hathitrust, 2014
"A district court ruled that libraries that provided a search engine
company (Google) with books to scan were protected by fair use when
the libraries later used the resulting digital scans for three
purposes: preservation, a full-text search engine, and electronic
access for disabled patrons who could not read the print versions. On
appeal, the Second Circuit affirmed fair use as to the full-text
database (“a quintessentially transformative use”) and as to use of
text in formats accessible to print-disabled people (although not a
transformative use, it is still considered a fair use based on the
Betamax decision), but remanded the issue of fair use for long-term
preservation of books." ("Summaries of Fair Use Cases", Standford
Libraries)

*** Authors Guild v. Google, Inc., No. 13-4829 (2d Cir. 2015)
"Google made digital copies of millions of books submitted to it by
libraries, scanned them and made them available to search through its
Google Books service, so that users could—for free—identify relevant
words, terms, or snippets from the scanned text. Google also allowed
participating libraries to retain the copies they submitted. Important
factors: Google’s digitization was deemed a transformative use because
it provided limited information about the books without allowing users
more complete access to the works." ("Summaries of Fair Use Cases",
Standford Libraries)

*** “Winning the AI Race: Strengthening US Capabilities in Computing and Innovation.Sam Altman, Testimony, May 8:
- May 8 congressional hearing titled “Winning the AI Race:
  Strengthening US Capabilities in Computing and Innovation.”
- OpenAI CEO Sam Altman, Microsoft President Brad Smith, AMD CEO Dr.
  Lisa Su, and CoreWeave CEO Michael Intrator speaking to the Senate
  Commerce Committee.
- Argument: that the US requires free rein (low regulation) to defeat
  China in the "AI Race", we will know we win the race if we can
  innovate and export" 
- Cruz:
  - position: regulation is "needless" and "orwellian",
    "paternalistic". 
  - Cruz's contradictory language frames US as free, Europe and China
    as authoritarian.
    - Cruz's language contrasts "entrepreneurial freedom and
      technological innovation" against "command-and-control policies
      of Europe".
  - Drawing from history of the internet, which was developed with
    relatively low regulation in the USA.
    - Telecommunications Act of 1996 that promoted competition via
      deregulation, (but in reality, smoothed the road for
      consolidation, "going against its very stated intention by
      indirectly restricting newcomer access to broadcasting"
      (wikipedia, "Telecommunications Act of 1996")
  - Referring to Biden and some state legislatures: "They want a
    testing regime... seemingly something out of Orwell ... as if AI
    engineers lack the intelligence to responsibly build AI without
    the bureaucrats"
  - "U.S. dominance in AI depends on two factors: innovation and
    adoption."
- Altman:
  - vetting systems would be "disastrous" for industry, "sensible
    regulation that does not slow us down"
- Smith, microsoft president:
  - the way to know we've won the "race" is if our tech is broadly
    adopted.

*** NYTimes complaint
- NYT complaint argues that OpenAI "stea[s] audiences away from it",
  that outputs "compete", "closely mimic" NYT articles, and that the
  work is not "transformative". (page 4).


--> argumment seems to be about outputs being copies, when should be
about inputs?

*** 2018 OpenAI press release, december 12 2018, "Introducing OpenAI"
- OpenAI started as a nonprofit, and raised money with promises to
  share their products freely:
  - "Researchers will be strongly encouraged to publish their work,
    whether as papers, blog posts, or code, and our patents⁠ (if any)
    will be shared with the world" (OpenAI 12/11/2018 press release).

*** 2025 "OpenAI’s proposals for the U.S. AI Action Plan" march 13, 2025
- "we must ensure that people have freedom of intelligence, by which
  we mean the freedom to access and benefit from AI as it advances"
- "freedom-focused policy proposals"
- "neutralizes potential PRC benefit from American AI companies having
  to comply with overly burdensome state laws."
  - "freedom to innovate" regulations
  - "copyright strategy that promotes the freedom to learn"
    - "secure Americans’ freedom to learn from AI"
    - "avoid forfeiting our AI lead to the PRC"
  - "export strategy"
  - develop infrastructure
  - adoption by government

*** 2025 OSTP OSTP proposal, march 13, 2025
- Office of Science and Technology Policy proposal
- proposals to help OSTP develop "AI Action Plan ... that ensure[s]
  that American-led AI built on democratic principles continues to
  prevail over CCP-build autocratic, authoritarian AI".
- "democratic AI"
  - "a free market promoting free and fair competition.
  - "freedom for developers and users to work with our tools"
  - "preventing government use... to amass power and control their
    citizens"
- Deepseek is a threat because "simultaneously state-subsidized,
  state-controlled, and fully available... cost[ing] users privacy and
  security."
- point #3: "Copyright: Promoting the Freedom to Learn"
  - need to use copyrighted material to compete with China, a "matter
    of national security."
  - contradiction between China's "unfettered access" vs OpenAI's
    "fair use":
    - "Applying the fair use doctrine to AI is not only a matter of
      American competitiveness-—it’s a matter of national security.
      The rapid advances seen with the PRC’s DeepSeek, among other
      recent developments, show that America’s lead on frontier AI is
      far from guaranteed. Given concerted state support for critical
      industries and infrastructure projects, there’s little doubt
      that the PRC’s AI developers will enjoy unfettered access to
      data—including copyrighted data—that will improve their models.
      If the PRC’s developers have unfettered access to data and
      American companies are left without fair use access, the race
      for AI is effectively over. America loses, as does the success
      of democratic AI. Ultimately, access to more data from the
      widest possible range of sources will ensure more access to more
      powerful innovations that deliver even more knowledge" (10-11). 
*** 2023(?) OpenAI Comments on Intellectual Property Protection for Artificial Intelligence Innovation
- argue that, “Under current law, training AI systems constitutes fair
  use”
  - argument for fair use hinges on "transformative" use of copyrighted work
    - citing a passage from a court case that defends parody (Campbell
      v. Acuff-Rose Music) as fair use to argue that AI outputs are
      "highly transformative"
    - input data: copyrighted works become statistical patterns,
      “non-expressive”"
    - output data: nobody can use AI to read the specific webpages
      they are trained on: they will still go to NYTimes to read the
      news. (debatable).
- "mission is to ensure that artificial general intelligence (“AGI”)
  benefits all of humanity”"
- anthropomorphize AI training into human learning:
  - “does copyright law’s protection of an author’s original
    expression impede AI systems from generating insights about that
    expression?”
  - ““training” refers to the process by which an AI model learns
    patterns”
- “Authors may object that the outputs of generative AI systems will
  harm the value of their works. We address this objection in Section
  II.”
  - “Distributive Issues from AI-Generated Non-Infringing Works Should
    Be Addressed by Other Policies”
  - “this concern falls into a broader category of concerns about the
    relationship  between automation, labor, and economic growth”
  - "we believe that such distributive claims are most efficiently
    addressed through taxation and redistribution, rather than
    copyright policy.”
    - “Louis Kaplow & Steven Shavell, Why the Legal System Is Less
      Efficient than the Income Tax  in Redistributing Income, 23 J.
      Legal Stud. 667 (1994) (“[R]edistribution through legal rules
      offers no  advantage over redistributions through the income tax
      system and is typically less efficient.”).”

