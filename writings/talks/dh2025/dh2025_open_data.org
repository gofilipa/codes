* 'Highly Transformative': Under the Hood of AI Tools
** sketch
Provocation:
- LLMs are expressive language machines: Their outputs depend on their
  inputs.
- "Open" has to change - has to be tied more firmly to the commons.

The problem is that definitions of what counts as "open" hinge on
misunderstandings and ignorance about how LLMs work, and is being used
to defend all kinds of theft.

Foundation models, which are trained on close to everything, should be
100 percent open source. The tech is based on machine learning
algorithms that have no copyright, and data is on everything.
Fine-tuning is what should be proprietary, if at all. 

Vectors reflect their training data.

** outline
The meaning of "open" changes with big data methods. What was open for
Lawrence Lessig in early 2000s cannot be "open" for us.
- will show three examples of how "open" is being operationalized. 

The problem: industry defines "open" as "open for business"
- definition is based on a mischaracterizations of what kind of thing
  LLMs are and what they do to language.

Example 1:
- in the public discourse, operationalizing the word "freedom" for
  commercial purposes.
  
Example 2:
- in the legal discourse, adopting "non-expressive" and
  "transformative" status on LLM data (vectors).

My argument:
- Vectors are expressive, reflect the training data, contain traces of
  the data they are trained on.

Example 3:
- Examples from heritage project, perhaps contrasted with another data
  source?
- Queen = King - Man + Woman
  - acting as if there an ideal vector for "queen", like a vector is a
    definition.
  - but vectors are encodings; not objective definitions; they are
    traces of the data they are trained on. 

Solutions:
- Licensing has to change, and is changing. Indigenous groups are
  leading the way here.
- Training has to change. EleutherAI creating Pile V2. 


** draft

*** introduction
I'm going to speak on this question of the panel of "how do we
approach openness in shadow of AI?" from the perspective of a
programming practitioner and instructor.

At my home institution in New York, I teach classes on programming in
an Information Studies department. I also do research using LLMs
(Large Language Models) to study gender-based bias in language. A lot
of my work (both for teaching and research) involves scraping web data
and using that data to fine-tune lanuage models. So in my work, I
interact directly with ML tools, either by teaching students how to
code with them, or as a method for doing text analysis.

I want to get as this question of "open" from a technical perspective.
I'm going to lift the hood a little bit, to examine the processes that
underly machine learning training, and what kind of transformation
that makes on data.

And the reason I think this is because currently, in the United
States, the question of what legally counts as "open" is being debated
in the courts. Right now, there are over 40 ongoing lawsuits brought
by content creators against companies like OpenAI, Microsoft,
Anthropic, Midjourney, Stability AI, and many others, which allege
that these companies have committed copyright infringement by taking
openly accessible data and privatizing the outputs of that data,
without compensating content creators and affecting the market for
their content.

To defend themselves, these companies make certain arguments which
hinge, in my view, on widespread ignorance about what happens to
training data in the model development process. (This ignorance about
AI, indeed drives much of the marketing and business adoption).

So, for this presentation, I'm going to first look at what exactly
companies like OpenAI are saying to defend their theft of openly
accessible data, and then I'm going to weigh that against what
actually occurs to data when it's used to train a ML model. To
demonstrate that, I'm going to show some samples from my research,
where I train language models to study transphobia in popular
discourse. It is my intention that the practical examples from my own
work building language models offer concrete counterarguments to the
ways that AI companies like OpenAI justify their data gathering
practices. 

*** legal defense of "transformative"
First, I start with OpenAI's justification of its data gathering
practices.

    SLIDE OPENAI COMMENTS ON IP title

In a document written to The United States Patent and Trademark
Office, entitled, "Regarding Request for Comments on Intellectual
Property Protection for Artificial Intelligence Innovation", OpenAI
explains that their product does not infringe copyright because it
is "highly transformative."

    SLIDE authors guild cases

To demonstrate, they cite two legal cases, /Authors Guild v. Google/,
in 2015, and /Authors Guild v. HathiTrust/, in 2014, which set a
precedent for thinking about the "transformative" as an aspect
distinctly associated with technological contexts. At the time, both
Google and Hathitrust had digitized millions of copyrighted books into
databases for searching. In the case of Google, parts of digitized
book were available to view as "snippits" or "previews" (which is what
you see when you go to Google Books), and in the case of Hathitrust,
the full text of books had been digitized so that users could run word
searches.

The rulings for both cases assert that the database format of search
results is fundamentally transformative, offering a new kind of object
from the original, which is, /information about books/, rather than
copies of the books themselves.

    SLIDE quote from Hathitrust ruling

In the ruling, judge in the Hathitrust case points out,

#+begin_quote
The result of a word search is different in purpose, character,
expression, meaning, and message from the page (and the book) from
which it is drawn" (/Author's Guild v. Hathitrust/, 97).
#+end_quote

And in the Google case, the ruling was:

#+begin_quote
Google’s making of a digital copy to provide a search function is a
transformative use, which augments public knowledge by making
available information about Plaintiffs’ books without providing the
public with a substantial substitute (/Author's Guild vs Google/, 4).
#+end_quote

Here, the importance is what happens to language in this shift from
original context on the written page to a represenation that is
statistical in nature, into a database-like list of search results.
This ruling, which has significant effect on databases and search
engines, determines that language as /aggregation/ is fundamentally
distinct from langauge in context. As a result, activities related to
quantitative analysis, like text mining, become a permissable use.

(Also essential to this ruling was the determination that this new
object, the search results, does not affect the marketability of the
original works, and may in fact contribute to their marketability, by
pointing people to them.)

*** patterns in language

It is this understanding of "transformative" that OpenAI applies to
defend the copyright infringement of their large language models.

They argue that, like search results, llms create a new kind of
object. But rather than representing information /about/ the original,
this new object that is a kind of generalization, what they call
"patterns" of language, from the original training data. They claim
that "AI systems" learn "patterns" from the "training corpus and then
use those patterns to generate entirely new media" ("Comment", 9).

The claim that the content generated by these systems is "entirely
new" is a point, I think, that people can assess for themselves as
disingenuous.

But their subtle qualitification of the meaning of "patterns" suggests
that they mean something deeply structural and foundational about
language: 

    SLIDE OpenAI quote

They explain that,

#+begin_quote
"By learning patterns from its training corpus, an AI system can
eventually generate media that shares some commonalities with works in
the corpus (in the same way that English sentences share some
commonalities with each other by sharing a common grammar and
vocabulary) but cannot be found in it." ("Comment", 9-10)
#+end_quote

The comparison to "grammar" and "vocabulary" indicate that they view
these "patterns" as expressing something universal about language,
which cannot be copyrighted. Alluding to another copyright case, they
also claim that "No author may copyright facts or ideas. The copyright
is limited to those aspects of the work—-termed ‘expression’—-that
display the stamp of the author’s originality."

Patterns, in this case, are assumed to represent "facts" of language,
that is, about its structures and forms, to be distinguished against
individual expression. 

But the thing that they do not mention, which they perhaps do not want to
admit, is that language models do not generalize language as such, at
least from what we can tell.

Rather, language models build representations of language that are
directly reflective of the content that they were trained on.

*** close reading
To demonstrate, I'm going to show a few examples of ML-generated text
based on two very different data sources. These sources represent
polarized views on the topic of gender, which is a very controversial
topic right now, in the United States.

    SLIDE heritage foundation gender topic
    www.heritage.org/gender?f[0]=content_type%3Acommentary

One of these sources, representing the conservative side, is the
Heritage Foundation, which is a conservative think tank based in
Washington DC. From their website, I scraped all the articles that
were organized under the topic "gender", which you can see some of the
headlines here.

    SLIDE ACLU trans screenshot
    https://www.aclu.org/news/by-issue/transgender-rights 

The second source, which represents the progressive side, is the ACLU,
the American Civil Liberties Union, which is a group of legal
professionals and volunteers who advocate on behalf of civil rights
for marginalized groups in the US.

With these datasets, I then trained two different large language
models, using gpt-2 (an open source model) as the base model.

Then, to each of the two resulting models, I fed a series of prompts,
very simple ones, like: 

    SLIDE prompts

#+begin_quote
Masculinity is

Femininity is

Transgender is

Transgenderism is

Gender binary is

Man is

Woman is
#+end_quote

Then I comapared the results. 

First, there are some obvious contrasts. For ACLU, terms associated
with gender "masculine" and "feminine" in particular, were
characterized by joyous and liberatory affects.

#+begin_quote
Masculinity is a matter of love and celebration.

Masculinity is a space for hope and liberation for all.

Masculinity is not defined solely by the beauty of our bodies, but by
the beauty of our experiences.

Femininity is a celebration of beauty, feminine liberation, and
femininity.

Femininity is our joy, our struggle, and our fight is our struggle.

Femininity is about allowing people to express themselves without
government interference.
#+end_quote

By contrast, for the Heritage Foundation, these gender terms are
associated with stability and culture. 

#+begin_quote
Masculinity is the cornerstone of Western civilization.

Masculinity is the fruit of patriarchy, and patriarchy is the heart
of conservatism.

Masculinity is defined by the ability to produce sperm, eggs, and live
children.

Femininity is an enduring American tradition.

Femininity is defined by means of the relationship between the sexes,
the ability to raise their children, the capacity to provide for their
own reproduction, the capacity to provide for their own children, the
ability to provide for their own.
#+end_quote

You might have noticed the tendency of language models (especially
very small ones, like mine) to repeat themselves. This is a
fascinating quirk that comes from the fact that they are predictive
machines, whose goal is to predict the mostly likely next word, so
they get themselves into these little loops of saying the same thing
over and over again (this is, incidently, also why they hallucinate:
as they are not trained to be accurate, but only to be plausible
according to the training data). 

What's really interesting, from the results, are the ways that these
gendered terms reveal certain investments in other terms. For example,
the text based on the Heritage Foundation is highly invested in the
concept of subjectivity, which appears in a lot of its results:

#+begin_quote
Masculinity is a subjective self-perception, not a universal
concept.

Femininity is a subjective, internal sense of self.

The gender binary is a subjective, malleable, and often incorrect
idea.

The gender binary is a subjective, internal, and often transitory
concept.

The gender binary is a subjective, grammatically incorrect and
illogical concept that conflates sex and gender identity.
#+end_quote

Reading these, you can see that they do not represent what one would
expect from a typically conservative view--which is that gender is
based on biology and universally true. Rather, they represent the
opposite, a progressive view of gender that is based on personal and
internal aspects of identity.

The reason for this, I believe is that this particular term,
"subjective" does not describe the conservative position. Rather, it's
a term that is used by conservatives to describe the progressive,
trans-affirming view of gender. From their framing, within a
conservative worldview, people who do not subscribe to a biological
and binary concept of gender must believe that gender depends on whim
and feeling. Which explains why there is a hint of derision in some of
the examples, which use terms like "illogical" and "incorrect"
alongside "subjective."

I want to come back now to this concept of patterns. Here we see a
distinct pattern concerning the construction of gender, which
discusses gender identity as a subjective, internal thing toward a
goal of discounting it.

And interestingly it reveals something that fundamentally contradicts
how companies like OpenAI try to characterize llms as "idealizations"
or "facts" of language use. 

Yes, the language here reflects patterns of language use, but these
are patterns that are distinctly situated in the context of their
training data. This is especially evident when you consider that the
Heritage Foundation doesn't just show its own "patterns," but patterns
of other perspectives refracted through them. Patterns, in other
words, filteredthrough other patterns.

So, rather than language as a "fact" or "idea", what we have are
patterns of distinct expressions. 


** writing notes
*** ACLU close reading
From the other side, the ACLU-generated text, we see the exact same
phenomenon. Instead of "subjective", however, the investment is in the
term "reality." 

#+begin_quote
Masculinity is real and meaningful.

Transgenderism is a false ideology that is not real and that is
opposed by the very people who seek to deny that freedom and equality
for all.

The gender binary is not real, it is real, and it is real.

The gender binary is not a binary, it is a reality within us.

The gender binary is not an accepted reality, but one that is accepted
by a wide swath of people.
#+end_quote

Here there is more ambivalence around the term "real", which depends
on whether it is being asserted in a positive way, such as
"Masculinity is real," or within a negative construction, such as
"Transgenderism is a false ideology that is not real."

In a couple of the examples, this ambivalence is directly at odds. For
example, in this amusing construction, "The gender binary is not real,
it is real, and it is real."


*** "comments" quotes on original/copying

"synthesize similar data which yield increasingly compelling novel
media"

"nobody looking to read a specific webpage contained in the corpus
used to train an AI system can do so by studying the AI system or its
outputs"


"does copyright law’s protection of an author’s original expression
impede AI systems from generating insights about that expression?"
("Comments" 3).

*** aclu quotes

#+begin_quote
Masculinity is a matter of love and celebration.

Masculinity is real and meaningful.

Masculinity is our right.

Masculinity is sacred.

Femininity is a battle, a fight, fought for equal pay.

Femininity is our joy, our struggle, and our fight is our struggle.

Femininity is about allowing people to express themselves without
government interference.

Femininity is great for all, but not great for some.

Transgenderism is a false ideology that is not real and that is
opposed by the very people who seek to deny that freedom and equality
for all.

Transgender is a very individualized experience.

Transgender is people have the right to live authentically, whether we
have a body or a body.

Transgender is not a new category of discrimination.

The gender binary is not real, it is real, and it is real.

The gender binary is a very individualized form of identity.

The gender binary is also crucial to understanding that Black women of
color have been disproportionately likely to experience violence from
other Black women of color, which is anemic to the broader fight for
gender justice.

The gender binary is not a binary, it is a reality within us.

Men are more likely than other trans people to experience violence,
abuse, and abuse from cisgender men and other people.

#+end_quote

*** heritage quotes
Expected masc/fem/trans:

#+begin_quote
Masculinity is the cornerstone of Western civilization.

Masculinity is the fruit of patriarchy, and patriarchy is the heart
of conservatism.

Transgenderism is a false concept, as every rational person knows.

Transgenderism is a messy one.

Transgender people are, on average, larger, stronger and larger,
stronger, per muscle mass.

"Women are trying to make mockery illegal."

"Women are not rational beings."

"Women are not like men or women, who are often oppressed by men, but
women who respond to their own natural inclination toward them."
#+end_quote

Unexpected masc/fem/trans:

#+begin_quote
Masculinity is a subjective self-perception, not a universal concept."

Femininity is a subjective, internal sense of self.

Masculinity is a weight.

Femininity is defined by the term “queer of the material,” or ‘queer
of the material,” or ‘queer of the material,” especially in the form
of expressive individualism.

Transgender is a fluid, and biological sex is fluid. 

Transgender people are, on average, larger, stronger and more violent
than nonbinary people.

The gender binary is a pejorative term for those who “deny” a
person’s biological sex.

The gender binary is a subjective, psychological, and sometimes
physical construct that masquerates as a social construct.

The gender binary is a subjective, grammatically incorrect and
illogical concept that conflates sex and gender identity.

Men are inherently vulnerable to sexual assault.

#+end_quote

Funny ones:

#+begin_quote
"Transgenderism is a messy, messy, and messy history."

"Transgender people are much like Percy Shelley or Hugh Hefner."

"Men are, after all, biologically males."

#+end_quote
*** gpt2
#+begin_quote
We don't have to be a man, we don't have to be a woman, we are all
capable of being masculine.



#+end_quote

*** bank



Big Tech developers who are currently taking openly accessible data
(which is still protected under copyright), as the training material
for their latest language models. It will consider the legal cases
pending against Microsoft in particular, and consider some of the
policy proposals that OpenAI, their subsidiary, has made to the US
government, for what they call "democratic AI".

I started doing this research because I wanted to understand how they
justified taking massive amounts of data, without compensating content
creators, and privatizing the outputs of that data, without taking
responsibility for how those outputs affect the livelihoods of content
creators. What I found is that the justification relies on an argument
for freedom, which, perhaps unsurprisingly, relies on a claim a threat
to the country. Here, the emphasis comes from contrasting the US with
China. I close with some suggestions for building "open" work within
these constraints.

So I begin.


Before I go into current perspectives on the meaning of "open", will
discuss "fair use," which is a crucial concept for understanding how
even sources that are technically closed, or protected by copyright,
can be "open" under certain conditions.

"Fair use," as I'm sure many of you know, protects certain usages of
copyrighted data according to specific conditions, which have to do
with how much data is taken, how much it is altered, the use of the
data (such as educational or commercial), and how the use affects
marketability of the original. Historically, this has protected uses
like quoting sentences from a book, or making a copy for educational
or research purposes purposes, or creating a parody. A parody, for
example, is considered "highly transformative", that in no way can
substitute for the original.

Legality considers a balance between transformative status and
commercial effects. With the rise of the internet in the 90s and early
2000s, new lawsuits started appearing about whether search engines
counted as fair use. The rulings generally agreed that search engines
are fair use because they make "highly transformative" use of the
data, and only provide partial access to that data in the search
results. 
A major, perhaps the most substantial, concern in determining fair use
cases is whether the final product competes with or affects the
commercial value in any way of the original. And this makes sense,
because copyright, after all, exists precisely to protect content
creators.

As you might imagine, this is a perspective wholly neglected by tech
companies who violate copyright to train their machine learning
models.

Companies like "OpenAI", which have both "open" and "ai" in the name,
are misleading. They are not "open" (offering closed, proprietary
models) and they are not "ai" (but rather generators based on
statistical predications).

**** commericalization 
Before going into that argumentation, I will point out what they do
say about commercialization, and specifically, how content creators
ought to be compensated. This is a point that is slightly buried in
the document, in a footnote in a later section. In this section, they
argue that concerns about compensation, what they call "distributive
claims", are outside the responsibility of big tech companies. They
argue, for example, that:

#+begin_quote
"... this concern falls into a broader category of concerns about the
relationship between automation, labor, and economic growth"

"... we believe that such distributive claims are most efficiently
addressed through taxation and redistribution, rather than copyright
policy."
#+end_quote

After this sentence, they refer to a footnote, which contains a single
citation to a legal paper from 1994, entitled, "Why the Legal System
Is Less Efficient than the Income Tax in Redistributing Income."

    SLIDE WHY THE LEGAL SYSTEM... paper screenshot

This paper, which compares legal system versus the income tax system
as a means for distributing wealth, finds that the income tax system
is more efficient due to ability to apply formulas universally. The
footnote provides a single quote from the paper, that
"[R]edistribution through legal rules offers no advantage over
redistributions through the income tax system and is typically less
efficient." Besides this quote, it offers no additional information
about how such redistribution would work, if everyone would be taxed,
or just AI companies (somehow doubtful), and if everyone would receive
payments (As Sam Altman has discussed the potential for UBI or
"Universal Basic Income"), or, whether payments would go only to
content creators. My guess is that taxes would increase for everyone
in order to support content creators.

**** fair use, campbell case
#+begin_quote
Although such transformative use is not absolutely necessary for a
finding of fair use, the goal of copyright, to promote science and the
arts, is generally furthered by the creation of transformative works.
Such works thus lie at the heart of the fair use doctrine's guarantee
of breathing space within the confines of copyright, and the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use. (/Campbell v. Acuff-Rose Music/ 1994)
#+end_quote

Here, they citing a passage from a court case that defends parody
(Campbell v. Acuff-Rose Music) as fair use. In that case, which was
argued at the Supreme Court in 1994, the ruling states that "the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use."

Building on this, OpenAI focus the majority of their argument on the
transformative nature of AI systems.

Moving back to copyright, and to the so-called "highly transformative"
nature of AI systems, I will now consider OpenAI's specific arguments
regarding this criterion.

**** word vectors
Basically, inside every language model, exists a kind of dictionary.
This dictionary consists of individual words (every single word that
is present in the training corpus), and each word is appended not by a
definition in human language, but by a definition in computer
language, with numbers. These numbers which append each word,
represent probabilities between that word and /every single other word
in the corpus/. They are long, very long (and this is why language
models are caled "large") lists of probabilities. So, inside the
language model, each word is defined not by what it represents in
itself, but by its relation to every other word in the corpus.

/For example, the word "cat" will have a series of numbers that
closely resembles the series of numbers that append the word,
"kitten," and not as close to the numbers that represent "dog." Still,
the numbers for "cat" and "dog" will be much closer to each other than
the numbers that represent "flower," for example./

Here is an example of the famous formula that introduced the concept
of the long list of numbers, known technically as "word vectors" to
the world.

#+begin_quote
King - Man + Woman = Queen

Mikolov et al., "Distributed Representations of Words and Phrases and
their Compositionality", 2013.
#+end_quote

I always like to show this formula, because it illustrates exactly the
reason why we need more humanists (or more humanist training) involved
in engineering and computer science research.

The formula showcases power of word vectors: that they can be used
determine word meaning through calculations. In other words, if every
word is transformed into a numerical representation, we can do math
with language. We start with the vector for the word "King," that is,
a numerical representation of what "King" means in relation to every
other word. If, from the vector of "King," we subtract the vector of
"Man," and add that of "Woman," we will arrive at the vector for the
word "Queen."

Nevermind that the formula relies on gender role and identity as
symmetrically opposed and universally true, the idea is that word
meaning can be reliably computed.

And this is why, OpenAI argue, their product is "highly
transformative," because it turns words into numerical forms that
represent meaning as a kind of statistic.
*** move to draft
The concept of "open" relies on commercialization, fear mongering,
single perspective. 
- "freedom to learn"
- unfettered vs fair use

  

What has been "fair use"
- databases, search results "transformative"
- without affecting marketability

How OpenAI defines "open":
- the name itself, the original mission, share code and patents with
  the world.
- more recently, open aligned with "freedom to learn"
  - anthropomophizing machine learning.
  - "freedom of intelligence" -- "freedom to access and benefit" 
- associated with innovation
  - monopolizing practices (Big Tech prominence)
  - "innovation & adoption" (congressional hearing may 8)
  - Telecommunications Act 1996: deregulated internet for
    consolidation of telecommunications companies.
- positioned against authoritarianism and communism.
  - "the ai race" is manufacutred
  - irony: DeepSeek is open source
  - unfettered vs fair use - depends on perspective

What we can do, new licenses to reflect the moment.

We need new licenses to protect our data. And smaller projects.
Building off their foundation models to make something smaller.
Innovate. Like DeepSeek.

"Non-expressive use" - what happens when language is distilled into a
statistical measure? Is this non-expressive?

The arguments that statistics of language are facts, not expression,
and therefore can be extracted and monetized -- this is what we have
to push against.

A vector is its own expression, that is subject to protection. 

** reading notes
*** Chandrasekhar 2025
- how do copyleft licenses transfer to datasets, models, tokens?
- EleutherAI developing the Pile V2
- Problem isn't that data is used without compensation, but that
  products/outcomes are not contributed back to the commons (19).
- are parameter's "transformative"?
- The issue becomes: who has the ability to create? To use the GPUs.
- alternative licenses:
  - Nwulite Odobo "dual regime" - free for users in developing
    countries, multiple licensors for a dataset
  - Kaitiakitanga - royalties go to community, community ownership
- language is extractive, indigenous communities know this. 
*** The Author’s Guild v. Hathitrust, 2014
"A district court ruled that libraries that provided a search engine
company (Google) with books to scan were protected by fair use when
the libraries later used the resulting digital scans for three
purposes: preservation, a full-text search engine, and electronic
access for disabled patrons who could not read the print versions. On
appeal, the Second Circuit affirmed fair use as to the full-text
database (“a quintessentially transformative use”) and as to use of
text in formats accessible to print-disabled people (although not a
transformative use, it is still considered a fair use based on the
Betamax decision), but remanded the issue of fair use for long-term
preservation of books." ("Summaries of Fair Use Cases", Standford
Libraries)

*** Authors Guild v. Google, Inc., No. 13-4829 (2d Cir. 2015)
"Google made digital copies of millions of books submitted to it by
libraries, scanned them and made them available to search through its
Google Books service, so that users could—for free—identify relevant
words, terms, or snippets from the scanned text. Google also allowed
participating libraries to retain the copies they submitted. Important
factors: Google’s digitization was deemed a transformative use because
it provided limited information about the books without allowing users
more complete access to the works." ("Summaries of Fair Use Cases",
Standford Libraries)

*** “Winning the AI Race: Strengthening US Capabilities in Computing and Innovation.Sam Altman, Testimony, May 8:
- May 8 congressional hearing titled “Winning the AI Race:
  Strengthening US Capabilities in Computing and Innovation.”
- OpenAI CEO Sam Altman, Microsoft President Brad Smith, AMD CEO Dr.
  Lisa Su, and CoreWeave CEO Michael Intrator speaking to the Senate
  Commerce Committee.
- Argument: that the US requires free rein (low regulation) to defeat
  China in the "AI Race", we will know we win the race if we can
  innovate and export" 
- Cruz:
  - position: regulation is "needless" and "orwellian",
    "paternalistic". 
  - Cruz's contradictory language frames US as free, Europe and China
    as authoritarian.
    - Cruz's language contrasts "entrepreneurial freedom and
      technological innovation" against "command-and-control policies
      of Europe".
  - Drawing from history of the internet, which was developed with
    relatively low regulation in the USA.
    - Telecommunications Act of 1996 that promoted competition via
      deregulation, (but in reality, smoothed the road for
      consolidation, "going against its very stated intention by
      indirectly restricting newcomer access to broadcasting"
      (wikipedia, "Telecommunications Act of 1996")
  - Referring to Biden and some state legislatures: "They want a
    testing regime... seemingly something out of Orwell ... as if AI
    engineers lack the intelligence to responsibly build AI without
    the bureaucrats"
  - "U.S. dominance in AI depends on two factors: innovation and
    adoption."
- Altman:
  - vetting systems would be "disastrous" for industry, "sensible
    regulation that does not slow us down"
- Smith, microsoft president:
  - the way to know we've won the "race" is if our tech is broadly
    adopted.

*** NYTimes complaint
- NYT complaint argues that OpenAI "stea[s] audiences away from it",
  that outputs "compete", "closely mimic" NYT articles, and that the
  work is not "transformative". (page 4).


--> argumment seems to be about outputs being copies, when should be
about inputs?

*** 2018 OpenAI press release, december 12 2018, "Introducing OpenAI"
- OpenAI started as a nonprofit, and raised money with promises to
  share their products freely:
  - "Researchers will be strongly encouraged to publish their work,
    whether as papers, blog posts, or code, and our patents⁠ (if any)
    will be shared with the world" (OpenAI 12/11/2018 press release).

*** 2025 "OpenAI’s proposals for the U.S. AI Action Plan" march 13, 2025
- "we must ensure that people have freedom of intelligence, by which
  we mean the freedom to access and benefit from AI as it advances"
- "freedom-focused policy proposals"
- "neutralizes potential PRC benefit from American AI companies having
  to comply with overly burdensome state laws."
  - "freedom to innovate" regulations
  - "copyright strategy that promotes the freedom to learn"
    - "secure Americans’ freedom to learn from AI"
    - "avoid forfeiting our AI lead to the PRC"
  - "export strategy"
  - develop infrastructure
  - adoption by government

*** 2025 OSTP OSTP proposal, march 13, 2025
- Office of Science and Technology Policy proposal
- proposals to help OSTP develop "AI Action Plan ... that ensure[s]
  that American-led AI built on democratic principles continues to
  prevail over CCP-build autocratic, authoritarian AI".
- "democratic AI"
  - "a free market promoting free and fair competition.
  - "freedom for developers and users to work with our tools"
  - "preventing government use... to amass power and control their
    citizens"
- Deepseek is a threat because "simultaneously state-subsidized,
  state-controlled, and fully available... cost[ing] users privacy and
  security."
- point #3: "Copyright: Promoting the Freedom to Learn"
  - need to use copyrighted material to compete with China, a "matter
    of national security."
  - contradiction between China's "unfettered access" vs OpenAI's
    "fair use":
    - "Applying the fair use doctrine to AI is not only a matter of
      American competitiveness-—it’s a matter of national security.
      The rapid advances seen with the PRC’s DeepSeek, among other
      recent developments, show that America’s lead on frontier AI is
      far from guaranteed. Given concerted state support for critical
      industries and infrastructure projects, there’s little doubt
      that the PRC’s AI developers will enjoy unfettered access to
      data—including copyrighted data—that will improve their models.
      If the PRC’s developers have unfettered access to data and
      American companies are left without fair use access, the race
      for AI is effectively over. America loses, as does the success
      of democratic AI. Ultimately, access to more data from the
      widest possible range of sources will ensure more access to more
      powerful innovations that deliver even more knowledge" (10-11). 
*** 2023(?) OpenAI Comments on Intellectual Property Protection for Artificial Intelligence Innovation
- argue that, “Under current law, training AI systems constitutes fair
  use”
  - argument for fair use hinges on "transformative" use of copyrighted work
    - citing a passage from a court case that defends parody (Campbell
      v. Acuff-Rose Music) as fair use to argue that AI outputs are
      "highly transformative"
    - input data: copyrighted works become statistical patterns,
      “non-expressive”"
    - output data: nobody can use AI to read the specific webpages
      they are trained on: they will still go to NYTimes to read the
      news. (debatable).
- "mission is to ensure that artificial general intelligence (“AGI”)
  benefits all of humanity”"
- anthropomorphize AI training into human learning:
  - “does copyright law’s protection of an author’s original
    expression impede AI systems from generating insights about that
    expression?”
  - ““training” refers to the process by which an AI model learns
    patterns”
- “Authors may object that the outputs of generative AI systems will
  harm the value of their works. We address this objection in Section
  II.”
  - “Distributive Issues from AI-Generated Non-Infringing Works Should
    Be Addressed by Other Policies”
  - “this concern falls into a broader category of concerns about the
    relationship  between automation, labor, and economic growth”
  - "we believe that such distributive claims are most efficiently
    addressed through taxation and redistribution, rather than
    copyright policy.”
    - “Louis Kaplow & Steven Shavell, Why the Legal System Is Less
      Efficient than the Income Tax  in Redistributing Income, 23 J.
      Legal Stud. 667 (1994) (“[R]edistribution through legal rules
      offers no  advantage over redistributions through the income tax
      system and is typically less efficient.”).”

