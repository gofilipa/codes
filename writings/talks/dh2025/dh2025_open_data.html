<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-07-10 Thu 14:01 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="fcalado" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#org45bf1fe">1. draft</a>
<ul>
<li><a href="#org4603efb">1.1. introduction</a></li>
<li><a href="#orgc1cf6c3">1.2. legal defense of "transformative"</a></li>
<li><a href="#org0c5acf5">1.3. patterns in language</a></li>
<li><a href="#org9d514f2">1.4. close reading</a></li>
</ul>
</li>
</ul>
</div>
</div>
<div id="outline-container-org45bf1fe" class="outline-2">
<h2 id="org45bf1fe"><span class="section-number-2">1.</span> draft</h2>
<div class="outline-text-2" id="text-1">
</div>
<div id="outline-container-org4603efb" class="outline-3">
<h3 id="org4603efb"><span class="section-number-3">1.1.</span> introduction</h3>
<div class="outline-text-3" id="text-1-1">
<p>
I'm going to speak on this question of the panel of "how do we
approach openness in shadow of AI?" from the perspective of a
programming practitioner and instructor.
</p>

<p>
At my home institution in New York, I teach classes on programming in
an Information Studies department. I also do research using LLMs
(Large Language Models) to study gender-based bias in language. A lot
of my work (both for teaching and research) involves scraping web data
and using that data to fine-tune lanuage models. So in my work, I
interact directly with ML tools, either by teaching students how to
code with them, or as a method for doing text analysis.
</p>

<p>
I want to get as this question of "open" from a technical perspective.
I'm going to lift the hood a little bit, to examine the processes that
underly machine learning training, and what kind of transformation
that makes on data.
</p>

<p>
And the reason I think this is because currently, in the United
States, the question of what legally counts as "open" is being debated
in the courts. Right now, there are over 40 ongoing lawsuits brought
by content creators against companies like OpenAI, Microsoft,
Anthropic, Midjourney, Stability AI, and many others, which allege
that these companies have committed copyright infringement by taking
openly accessible data and privatizing the outputs of that data,
without compensating content creators and affecting the market for
their content.
</p>

<p>
To defend themselves, these companies make certain arguments which
hinge, in my view, on widespread ignorance about what happens to
training data in the model development process. (This ignorance about
AI, indeed drives much of the marketing and business adoption).
</p>

<p>
So, for this presentation, I'm going to first look at what exactly
companies like OpenAI are saying to defend their theft of openly
accessible data, and then I'm going to weigh that against what
actually occurs to data when it's used to train a ML model. To
demonstrate how this works in practice, I'm going to show some samples
from my research, where I train language models to study transphobia
in popular discourse. 
</p>
</div>
</div>

<div id="outline-container-orgc1cf6c3" class="outline-3">
<h3 id="orgc1cf6c3"><span class="section-number-3">1.2.</span> legal defense of "transformative"</h3>
<div class="outline-text-3" id="text-1-2">
<p>
First, I start with OpenAI's justification of its data gathering
practices.
</p>

<p>
SLIDE OPENAI COMMENTS ON IP title
</p>

<p>
In a document written to The United States Patent and Trademark
Office, entitled, "Regarding Request for Comments on Intellectual
Property Protection for Artificial Intelligence Innovation", OpenAI
explains that their product does not infringe copyright because it
is "highly transformative."
</p>

<p>
SLIDE authors guild cases
</p>

<p>
To demonstrate, they cite two legal cases, <i>Authors Guild v. Google</i>,
in 2015, and <i>Authors Guild v. HathiTrust</i>, in 2014, which set a
precedent for thinking about the "transformative" as an aspect
distinctly associated with technological contexts. At the time, both
Google and Hathitrust had digitized millions of copyrighted books into
databases for searching. In the case of Google, parts of digitized
book were available to view as "snippits" or "previews" (which is what
you see when you go to Google Books), and in the case of Hathitrust,
the full text of books had been digitized so that users could run word
searches.
</p>

<p>
The ruling for both cases assert that the database format of search
results is fundamentally transformative of the original, offering a
new kind of object, which is, <i>information about books</i>, rather than
copies of the books themselves. 
</p>

<p>
SLIDE quote from Hathitrust ruling
</p>

<p>
In the ruling, judge in the Hathitrust case points out,
</p>

<blockquote>
<p>
The result of a word search is different in purpose, character,
expression, meaning, and message from the page (and the book) from
which it is drawn" (<i>Author's Guild v. Hathitrust</i>, 97).
</p>
</blockquote>

<p>
And in the Google case, the ruling was:
</p>

<blockquote>
<p>
Google’s making of a digital copy to provide a search function is a
transformative use, which augments public knowledge by making
available information about Plaintiffs’ books without providing the
public with a substantial substitute (<i>Author's Guild vs Google,
2015</i>, 4).
</p>
</blockquote>

<p>
Here, the importance is the transformation of language from its
original context on the written page to a represenation that is
statistical in nature, into a database-like list of search results.
This ruling, which has significant effect on databases and search
engines, determines that language as <i>aggregation</i> is fundamentally
distinct from langauge in context. As a result, activities related to
quantitative analysis, like text mining, become a permissable use.
</p>

<p>
Also essential to this ruling was the determination that this new
object, the search results, does not affect the marketability of the
original works, and may in fact contribute to their marketability, by
pointing people to them.
</p>
</div>
</div>

<div id="outline-container-org0c5acf5" class="outline-3">
<h3 id="org0c5acf5"><span class="section-number-3">1.3.</span> patterns in language</h3>
<div class="outline-text-3" id="text-1-3">
<p>
It is this understanding of "transformative" that OpenAI applies to
defend the copyright infringement of their large language models.
</p>

<p>
They argue that, like search results, llms create a new kind of
object. But rather than representing information <i>about</i> the original,
this new object that is a kind of generalization, what they call
"patterns" of language, from the original training data. They claim
that "AI systems" learn "patterns" from the "training corpus and then
use those patterns to generate entirely new media" ("Comment", 9).
</p>

<p>
The claim that the content generated by these systems is "entirely
new" is a point, I think, that people can assess for themselves as
disingenuous.
</p>

<p>
But their subtle qualitification of the meaning of "patterns" suggests
that they mean something deeply structural and foundational about
language: 
</p>

<p>
SLIDE OpenAI quote
</p>

<p>
They explain that,
</p>

<blockquote>
<p>
"By learning patterns from its training corpus, an AI system can
eventually generate media that shares some commonalities with works in
the corpus (in the same way that English sentences share some
commonalities with each other by sharing a common grammar and
vocabulary) but cannot be found in it." ("Comment", 9-10)
</p>
</blockquote>

<p>
"No author may copyright facts or ideas. The copyright is limited to
those aspects of the work—-termed ‘expression’—-that display the stamp
of the author’s originality."
</p>

<p>
The comparison to "grammar" and "vocabulary" indicate that they view
patterns as analogous 
</p>

<p>
(Here, they assume patterns to be abstracted, generalized, idealized,
 but patterns are materially situated)
</p>

<p>
What they refer to as patterns are statistical representations of
language, a numerical representation that encodes a words semantic
meaning to the langauge model.
</p>



<p>
But the thing that they do not mention, which they perhaps do not want to
admit, is that vectors are far from generalizations of language as a
fact of idea&#x2013; rather, vectors are specifically tied to the data on
which they were trained.
</p>

<p>
To demonstrate, I'm going to show a few examples of ML-generated text
based on two very different data sources.
</p>
</div>
</div>

<div id="outline-container-org9d514f2" class="outline-3">
<h3 id="org9d514f2"><span class="section-number-3">1.4.</span> close reading</h3>
<div class="outline-text-3" id="text-1-4">
<p>
I'm working on a project right now that uses Machine Learning to
study transphobia in text. I've been gathering datasets from
more conservative sources, like the Heritage Foundation, which is a
conservative think tank based in Washington DC.
</p>

<p>
SLIDE HERITAGE gender screenshot
www.heritage.org/gender?f[0]=content_type%3Acommentary   
</p>

<p>
From their website, I scraped all the articles that were organized
under the topic "gender", which you can see some of the headlines
here. 
</p>

<p>
I've also been gathering articles from more progressive sources, like
the ACLU, the American Civil Liberties Union, which is a group of
legal professionals and volunteers who advocate on behalf of civil
rights focued on immigrants, women, and trans people.
</p>

<p>
SLIDE ACLU trans screenshot
<a href="https://www.aclu.org/news/by-issue/transgender-rights">https://www.aclu.org/news/by-issue/transgender-rights</a> 
</p>

<p>
From both sources, I wanted to represent a contrast of perspectives on
gender and transgender. With these datasets, I then trained two very
small) large language models, using gpt-2 as the base model.
</p>

<p>
To the two resulting models, I fed a series of prompts, very simple
ones:
</p>

<p>
SLIDE prompts
</p>

<blockquote>
<p>
Masculinity is
</p>

<p>
Femininity is
</p>

<p>
Transgender is
</p>

<p>
Transgenderism is
</p>

<p>
Gender binary is
</p>

<p>
Man is
</p>

<p>
Woman is
</p>
</blockquote>

<p>
I'll show you some of the results here.
</p>

<p>
First, the obvious contrasts. For ACLU, terms associated with gender
"masculine" and "feminine" in particular, were characterized by joyous
and liberatory affects.
</p>

<blockquote>
<p>
Masculinity is a matter of love and celebration.
</p>

<p>
Masculinity is a space for hope and liberation for all.
</p>

<p>
Masculinity is not defined solely by the beauty of our bodies, but by
the beauty of our experiences.
</p>

<p>
Femininity is a celebration of beauty, feminine liberation, and femininity.
</p>

<p>
Femininity is a battle, a fight, fought for equal pay.
</p>

<p>
Femininity is our joy, our struggle, and our fight is our struggle.
</p>

<p>
Femininity is about allowing people to express themselves without government interference. 
</p>
</blockquote>

<p>
You can perhaps already see the tendency of llms (especially
pre-production ones) to repeat themselves. Which is a fascinating
quirk that I think comes from the fact that they are predictive
machines and get themselves into these predictive loops. 
</p>

<p>
By contrast, for the Heritage Foundation, these gender terms are
associated with stability and culture. 
</p>

<blockquote>
<p>
Masculinity is the cornerstone of Western civilization.
</p>

<p>
Masculinity is the fruit of patriarchy, and patriarchy is the heart
of conservatism.
</p>

<p>
Masculinity is defined by the ability to produce sperm, eggs, and live
children.
</p>

<p>
Femininity is an enduring American tradition.
</p>

<p>
Femininity is defined by means of the relationship between the sexes,
the ability to raise their children, the capacity to provide for their
own reproduction, the capacity to provide for their own children, the
ability to provide for their own.
</p>

<p>
Femininity is a cornerstone of our culture, and its impact on our
national and cultural achievements is far-reaching.
</p>
</blockquote>

<p>
Subjective by heritage
</p>
<ul class="org-ul">
<li>you get the sense that these represent quotes or their paraphrases
from the trans-affirming side.</li>
<li>"subjective" associated with individual, psychology, fluid,
malleable, internal, transitory, and also incorrect and illogical.</li>
</ul>

<blockquote>
<p>
Masculinity is a subjective self-perception, not a universal
concept.
</p>

<p>
Femininity is a subjective, internal sense of self.
</p>

<p>
The gender binary is a subjective, psychological, and sometimes
physical construct that masquerates as a social construct.
</p>

<p>
The gender binary is a subjective, fluid system of questions that can
easily be answered by a simple yes or no answer.
</p>

<p>
The gender binary is a subjective, malleable, and often incorrect
idea.
</p>

<p>
The gender binary is a subjective, psychological, and biological
construct that is used to measure one’s sexual orientation or gender
identity (“segregated identity,” or whatever one might want to say it
is.
</p>

<p>
The gender binary is a subjective, internal, and often transitory
concept.
</p>

<p>
The gender binary is a subjective, grammatically incorrect and
illogical concept that conflates sex and gender identity.
</p>
</blockquote>

<p>
Reality by ACLU. Characterized by ambivalence, whether something is a
reality or is not a reality, there is a contrast. Could be due to the
paraphrasing of conservative views. 
</p>

<blockquote>
<p>
Masculinity is real and meaningful.
</p>

<p>
Transgenderism is a very real problem.
</p>

<p>
Transgenderism is a false ideology that is not real and that is
opposed by the very people who seek to deny that freedom and equality
for all.
</p>

<p>
The gender binary is not real, it is real, and it is real.
</p>

<p>
The gender binary is not a reality invented by cisgender people.
</p>

<p>
The gender binary is a binary without any real physical and emotional
freedom.
</p>

<p>
The gender binary is not a binary, it is a reality within us.
</p>

<p>
The gender binary is not a reality that we cling to most as vestiges
of sexism and patriarchy.
</p>

<p>
The gender binary is not real, it operates on a very different level
of social isolation.
</p>

<p>
The gender binary is not an accepted reality, but one that is accepted
by a wide swath of people.
</p>
</blockquote>

<p>
We are speaking in terms of patterns: here we see two distinct
patterns around the concept of subjectivity and reality: one
perspective (the conservative) discusses gender identity as a
subjective, internal thing toward a goal of discounting it. Another
side (the progressive) defines reality through ambivalance, through
distinctions. 
</p>

<p>
And interestingly it reveals something that fundamentally contradicts
how companies like OpenAI try to characterize llms as "idealizations"
or "facts" of language use. 
</p>

<p>
Yes, the language here reflects generalizations from patterns, but
patterns have been filtered through other patterns.
</p>

<p>
There is a layering here, of the heritage and aclu perspectives: they
are themselves layering other perspectives beneath them. They are
quoting and paraphrasing from the opposite point of view.
</p>

<p>
Here, from ACLU, I cannot tell if this is pro or anti-trans:
</p>

<blockquote>
<p>

</p>

<p>
The gender binary is not a binary, it is a reality within us.
</p>
</blockquote>

<p>
So there is no "fact" or "idealized" level of language here, but
layers of distinct expressions. 
</p>
</div>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: fcalado</p>
<p class="date">Created: 2025-07-10 Thu 14:01</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
