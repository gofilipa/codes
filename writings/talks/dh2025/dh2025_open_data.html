<?xml version="1.0" encoding="utf-8"?>
<!DOCTYPE html PUBLIC "-//W3C//DTD XHTML 1.0 Strict//EN"
"http://www.w3.org/TR/xhtml1/DTD/xhtml1-strict.dtd">
<html xmlns="http://www.w3.org/1999/xhtml" lang="en" xml:lang="en">
<head>
<!-- 2025-07-07 Mon 12:18 -->
<meta http-equiv="Content-Type" content="text/html;charset=utf-8" />
<meta name="viewport" content="width=device-width, initial-scale=1" />
<title>&lrm;</title>
<meta name="author" content="fcalado" />
<meta name="generator" content="Org Mode" />
<style>
  #content { max-width: 60em; margin: auto; }
  .title  { text-align: center;
             margin-bottom: .2em; }
  .subtitle { text-align: center;
              font-size: medium;
              font-weight: bold;
              margin-top:0; }
  .todo   { font-family: monospace; color: red; }
  .done   { font-family: monospace; color: green; }
  .priority { font-family: monospace; color: orange; }
  .tag    { background-color: #eee; font-family: monospace;
            padding: 2px; font-size: 80%; font-weight: normal; }
  .timestamp { color: #bebebe; }
  .timestamp-kwd { color: #5f9ea0; }
  .org-right  { margin-left: auto; margin-right: 0px;  text-align: right; }
  .org-left   { margin-left: 0px;  margin-right: auto; text-align: left; }
  .org-center { margin-left: auto; margin-right: auto; text-align: center; }
  .underline { text-decoration: underline; }
  #postamble p, #preamble p { font-size: 90%; margin: .2em; }
  p.verse { margin-left: 3%; }
  pre {
    border: 1px solid #e6e6e6;
    border-radius: 3px;
    background-color: #f2f2f2;
    padding: 8pt;
    font-family: monospace;
    overflow: auto;
    margin: 1.2em;
  }
  pre.src {
    position: relative;
    overflow: auto;
  }
  pre.src:before {
    display: none;
    position: absolute;
    top: -8px;
    right: 12px;
    padding: 3px;
    color: #555;
    background-color: #f2f2f299;
  }
  pre.src:hover:before { display: inline; margin-top: 14px;}
  /* Languages per Org manual */
  pre.src-asymptote:before { content: 'Asymptote'; }
  pre.src-awk:before { content: 'Awk'; }
  pre.src-authinfo::before { content: 'Authinfo'; }
  pre.src-C:before { content: 'C'; }
  /* pre.src-C++ doesn't work in CSS */
  pre.src-clojure:before { content: 'Clojure'; }
  pre.src-css:before { content: 'CSS'; }
  pre.src-D:before { content: 'D'; }
  pre.src-ditaa:before { content: 'ditaa'; }
  pre.src-dot:before { content: 'Graphviz'; }
  pre.src-calc:before { content: 'Emacs Calc'; }
  pre.src-emacs-lisp:before { content: 'Emacs Lisp'; }
  pre.src-fortran:before { content: 'Fortran'; }
  pre.src-gnuplot:before { content: 'gnuplot'; }
  pre.src-haskell:before { content: 'Haskell'; }
  pre.src-hledger:before { content: 'hledger'; }
  pre.src-java:before { content: 'Java'; }
  pre.src-js:before { content: 'Javascript'; }
  pre.src-latex:before { content: 'LaTeX'; }
  pre.src-ledger:before { content: 'Ledger'; }
  pre.src-lisp:before { content: 'Lisp'; }
  pre.src-lilypond:before { content: 'Lilypond'; }
  pre.src-lua:before { content: 'Lua'; }
  pre.src-matlab:before { content: 'MATLAB'; }
  pre.src-mscgen:before { content: 'Mscgen'; }
  pre.src-ocaml:before { content: 'Objective Caml'; }
  pre.src-octave:before { content: 'Octave'; }
  pre.src-org:before { content: 'Org mode'; }
  pre.src-oz:before { content: 'OZ'; }
  pre.src-plantuml:before { content: 'Plantuml'; }
  pre.src-processing:before { content: 'Processing.js'; }
  pre.src-python:before { content: 'Python'; }
  pre.src-R:before { content: 'R'; }
  pre.src-ruby:before { content: 'Ruby'; }
  pre.src-sass:before { content: 'Sass'; }
  pre.src-scheme:before { content: 'Scheme'; }
  pre.src-screen:before { content: 'Gnu Screen'; }
  pre.src-sed:before { content: 'Sed'; }
  pre.src-sh:before { content: 'shell'; }
  pre.src-sql:before { content: 'SQL'; }
  pre.src-sqlite:before { content: 'SQLite'; }
  /* additional languages in org.el's org-babel-load-languages alist */
  pre.src-forth:before { content: 'Forth'; }
  pre.src-io:before { content: 'IO'; }
  pre.src-J:before { content: 'J'; }
  pre.src-makefile:before { content: 'Makefile'; }
  pre.src-maxima:before { content: 'Maxima'; }
  pre.src-perl:before { content: 'Perl'; }
  pre.src-picolisp:before { content: 'Pico Lisp'; }
  pre.src-scala:before { content: 'Scala'; }
  pre.src-shell:before { content: 'Shell Script'; }
  pre.src-ebnf2ps:before { content: 'ebfn2ps'; }
  /* additional language identifiers per "defun org-babel-execute"
       in ob-*.el */
  pre.src-cpp:before  { content: 'C++'; }
  pre.src-abc:before  { content: 'ABC'; }
  pre.src-coq:before  { content: 'Coq'; }
  pre.src-groovy:before  { content: 'Groovy'; }
  /* additional language identifiers from org-babel-shell-names in
     ob-shell.el: ob-shell is the only babel language using a lambda to put
     the execution function name together. */
  pre.src-bash:before  { content: 'bash'; }
  pre.src-csh:before  { content: 'csh'; }
  pre.src-ash:before  { content: 'ash'; }
  pre.src-dash:before  { content: 'dash'; }
  pre.src-ksh:before  { content: 'ksh'; }
  pre.src-mksh:before  { content: 'mksh'; }
  pre.src-posh:before  { content: 'posh'; }
  /* Additional Emacs modes also supported by the LaTeX listings package */
  pre.src-ada:before { content: 'Ada'; }
  pre.src-asm:before { content: 'Assembler'; }
  pre.src-caml:before { content: 'Caml'; }
  pre.src-delphi:before { content: 'Delphi'; }
  pre.src-html:before { content: 'HTML'; }
  pre.src-idl:before { content: 'IDL'; }
  pre.src-mercury:before { content: 'Mercury'; }
  pre.src-metapost:before { content: 'MetaPost'; }
  pre.src-modula-2:before { content: 'Modula-2'; }
  pre.src-pascal:before { content: 'Pascal'; }
  pre.src-ps:before { content: 'PostScript'; }
  pre.src-prolog:before { content: 'Prolog'; }
  pre.src-simula:before { content: 'Simula'; }
  pre.src-tcl:before { content: 'tcl'; }
  pre.src-tex:before { content: 'TeX'; }
  pre.src-plain-tex:before { content: 'Plain TeX'; }
  pre.src-verilog:before { content: 'Verilog'; }
  pre.src-vhdl:before { content: 'VHDL'; }
  pre.src-xml:before { content: 'XML'; }
  pre.src-nxml:before { content: 'XML'; }
  /* add a generic configuration mode; LaTeX export needs an additional
     (add-to-list 'org-latex-listings-langs '(conf " ")) in .emacs */
  pre.src-conf:before { content: 'Configuration File'; }

  table { border-collapse:collapse; }
  caption.t-above { caption-side: top; }
  caption.t-bottom { caption-side: bottom; }
  td, th { vertical-align:top;  }
  th.org-right  { text-align: center;  }
  th.org-left   { text-align: center;   }
  th.org-center { text-align: center; }
  td.org-right  { text-align: right;  }
  td.org-left   { text-align: left;   }
  td.org-center { text-align: center; }
  dt { font-weight: bold; }
  .footpara { display: inline; }
  .footdef  { margin-bottom: 1em; }
  .figure { padding: 1em; }
  .figure p { text-align: center; }
  .equation-container {
    display: table;
    text-align: center;
    width: 100%;
  }
  .equation {
    vertical-align: middle;
  }
  .equation-label {
    display: table-cell;
    text-align: right;
    vertical-align: middle;
  }
  .inlinetask {
    padding: 10px;
    border: 2px solid gray;
    margin: 10px;
    background: #ffffcc;
  }
  #org-div-home-and-up
   { text-align: right; font-size: 70%; white-space: nowrap; }
  textarea { overflow-x: auto; }
  .linenr { font-size: smaller }
  .code-highlighted { background-color: #ffff00; }
  .org-info-js_info-navigation { border-style: none; }
  #org-info-js_console-label
    { font-size: 10px; font-weight: bold; white-space: nowrap; }
  .org-info-js_search-highlight
    { background-color: #ffff00; color: #000000; font-weight: bold; }
  .org-svg { }
</style>
</head>
<body>
<div id="content" class="content">
<div id="table-of-contents" role="doc-toc">
<h2>Table of Contents</h2>
<div id="text-table-of-contents" role="doc-toc">
<ul>
<li><a href="#orge834de4">1. introduction</a></li>
<li><a href="#orgdc1020f">2. public &amp; legal discourse around what is open</a></li>
<li><a href="#orgf711b10">3. patterns in language</a></li>
<li><a href="#org0717b16">4. close reading</a></li>
</ul>
</div>
</div>
<div id="outline-container-orge834de4" class="outline-2">
<h2 id="orge834de4"><span class="section-number-2">1.</span> introduction</h2>
<div class="outline-text-2" id="text-1">
<p>
This presentation is about the concept of "open source" is changing in
light of big data methods associated with machine learning.
</p>

<p>
"Open" in a technical sense means something different today that it
did at the emergence of Open Source and open data. The use of such
data was not automated, so being "open" didn't have the same effect.
Now that we have methods for vaccuuming up that data at scale, and
creating products that compete with the original data, we need to
rethink "open."
</p>
</div>
</div>

<div id="outline-container-orgdc1020f" class="outline-2">
<h2 id="orgdc1020f"><span class="section-number-2">2.</span> public &amp; legal discourse around what is open</h2>
<div class="outline-text-2" id="text-2">
<p>
OpenAI, on how it presents itself around "open".
</p>

<p>
SLIDE OAI's original mission
</p>

<p>
OpenAI's original mission, from its release in 2018, declared the
company's "goal is to advance digital intelligence in the way that is
most likely to benefit humanity as a whole, unconstrained by a need to
generate financial return." It claimed that AI should be "as broadly
and evenly distributed as possible," and that its code, research and
patents, "will be shared with the world" (12/11/2018 press release).
</p>

<p>
More recently, this language has shifted from sharing to freedom.
</p>

<p>
SLIDE OIA freedom-focused policy proposals
</p>

<p>
In a proposal to the OSTP from march of this year, the company makes a
series of "freedom-focused policy proposals" which are apparently
based on democracic values.
</p>

<p>
This proposal lists a litany of freedoms, including the "freedom of
intelligence", "freedom to access and benefit", "freedom to innovate,"
"freedom to learn." The last one, "freedom to learn" concerns
copyright.
</p>

<blockquote>
<p>
We propose a copyright strategy that would extend the system’s role
into the Intelligence Age by protecting the rights and interests of
content creators while also protecting America’s AI leadership and
national security. The federal government can both secure Americans’
freedom to learn from AI, and avoid forfeiting our AI lead to the PRC
by preserving American AI models’ ability to learn from copyrighted
material.
</p>
</blockquote>

<p>
Here, interestingly, there are two learners: humans and AI. Not only
are the humans learning from AI, but the AI themselves are learning,
by taking copyrighted data as resources for "training."
</p>

<p>
Of course, in a discourse that already anthropomorphizes machine
learning tools as "intelligent", they are doing the same with
"learning". But "learning" for a machine is much different than a
human, leading to accelerated capacities not only in processing but
also in generating that a human cannot replicate.
</p>

<p>
But, the real justification for taking copyrighted data is buried in
the text here: a reference to competition with the "PRC", the Peoples'
Republic of China.
</p>

<p>
SLIDE OAI proposal text 
</p>

<p>
In the proposal text, we see this justification spelled out in more
detail. This is in a section entitled, "Copyright: Promoting the
Freedom to Learn",
</p>

<blockquote>
<p>
Applying the fair use doctrine to AI is not only a matter of American
competitiveness-—it’s a matter of national security. The rapid
advances seen with the PRC’s DeepSeek, among other recent
developments, show that America’s lead on frontier AI is far from
guaranteed. Given concerted state support for critical industries and
infrastructure projects, there’s little doubt that the PRC’s AI
developers will enjoy unfettered access to data—-including copyrighted
data—-that will improve their models. If the PRC’s developers have
unfettered access to data and American companies are left without fair
use access, the race for AI is effectively over. America loses, as
does the success of democratic AI. ("Proposal to OSTP")
</p>
</blockquote>

<p>
The context is DeepSeek, which was released by China in early 2025,
and accomplished impressive performance using a fraction of the
resources used by big tech companies in the US.
</p>

<p>
Here the bias emerges in the adjectives they use to describe data
collection: for China, it is "unfettered access", for the USA, it is
"fair use access". There is no difference between "unfettered" and
"fair use," because OpenAI (and other big tech companies) are not
limiting themselves in how they gather data.
</p>

<p>
They state,
</p>

<blockquote>
<p>
our AI model training aligns with the core objectives of copyright and
the fair use doctrine, using existing works to create something wholly
new and different without eroding the commercial value of those
existing works. ("Proposal to OSTP")
</p>
</blockquote>

<p>
The fair use hinges on this notion of "creating something wholly new
and different". This is a reference to one of the legal criteria for
"fair use," which is called the "transformative".
</p>

<p>
How they are operationalizing the "transformative" criterion is fully
spelled out in another document, also in response to a US government
request for information.
</p>

<p>
SLIDE OPENAI COMMENTS ON IP, quote campbell acuff-rose
</p>

<p>
To the United States Patent and Trademark Office, entitled, "Regarding
Request for Comments on Intellectual Property Protection for
Artificial Intelligence Innovation", OpenAI mounts their defence of
"fair use." This defense hinges on the status of AI technology as what
they call "highly transformative."
</p>

<blockquote>
<p>
Although such transformative use is not absolutely necessary for a
finding of fair use, the goal of copyright, to promote science and the
arts, is generally furthered by the creation of transformative works.
Such works thus lie at the heart of the fair use doctrine's guarantee
of breathing space within the confines of copyright, and the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use. (<i>Campbell v. Acuff-Rose Music</i> 1994)
</p>
</blockquote>

<p>
Here, they citing a passage from a court case that defends parody
(Campbell v. Acuff-Rose Music) as fair use. In that case, which was
argued at the Supreme Court in 1994, the ruling states that "the more
transformative the new work, the less will be the significance of
other factors, like commercialism, that may weigh against a finding of
fair use."
</p>

<p>
Building on this, OpenAI focus the majority of their argument on the
transformative nature of AI systems.
</p>

<p>
Before going into that argumentation, I will point out what they do
say about commercialization, and specifically, how content creators
ought to be compensated. This is a point that is slightly buried in
the document, in a footnote in a later section. In this section, they
argue that concerns about compensation, what they call "distributive
claims", are outside the responsibility of big tech companies. They
argue, for example, that:
</p>

<blockquote>
<p>
"&#x2026; this concern falls into a broader category of concerns about the
relationship between automation, labor, and economic growth"
</p>

<p>
"&#x2026; we believe that such distributive claims are most efficiently
addressed through taxation and redistribution, rather than copyright
policy."
</p>
</blockquote>

<p>
After this sentence, they refer to a footnote, which contains a single
citation to a legal paper from 1994, entitled, "Why the Legal System
Is Less Efficient than the Income Tax in Redistributing Income."
</p>

<p>
SLIDE WHY THE LEGAL SYSTEM&#x2026; paper screenshot
</p>

<p>
This paper, which compares legal system versus the income tax system
as a means for distributing wealth, finds that the income tax system
is more efficient due to ability to apply formulas universally. The
footnote provides a single quote from the paper, that
"[R]edistribution through legal rules offers no advantage over
redistributions through the income tax system and is typically less
efficient." Besides this quote, it offers no additional information
about how such redistribution would work, if everyone would be taxed,
or just AI companies (somehow doubtful), and if everyone would receive
payments (As Sam Altman has discussed the potential for UBI or
"Universal Basic Income"), or, whether payments would go only to
content creators. My guess is that taxes would increase for everyone
in order to support content creators.
</p>

<p>
Moving back to copyright, and to the so-called "highly transformative"
nature of AI systems, I will now consider OpenAI's specific arguments
regarding this criterion.
</p>

<p>
First, they cite two legal cases, Authors Guild v. Google, 2015, and
Authors Guild v. HathiTrust, 2014, that set a precendence for thinking
about the "transformative" as a factor that intersects interestingly
with technological contexts. Both cases were brought by the Authors
Guild, a professional organization for writers in the US, to argue
that search results violate copyright. At the time, both Google and
Hathitrust had digitazed thousands to millions (in the case of Google)
of copyrighted books into a database for searching, and users could
see excerpts and other information about the copyrighted works on the
Google and Hathitrust search engines.
</p>

<p>
The ruling for both cases assert that search results constitute
something distinct from the original, which is fundamentally
transformative, that is, <i>information about books</i>. Such information
does not offer a replacement or substitute for the book, but rather,
it offers a new kind of object. Here, the importance is the
transformation of language from its original context, in a sentence or
on a page, to a represenation that is statistical in nature,
representing part of an aggregation. As the judge in the Hathitrust
case points out, "the result of a word search is different in purpose,
character, expression, meaning, and message from the page (and the
book) from which it is drawn" (<i>Author's Guild v. Hathitrust</i>, 97).
These court cases, significantly for databases and search engines, set
activities related to quantitative analysis, like text mining, as a
permissable use.
</p>

<p>
OpenAI take this concept of the "transformative" and applies it in
full force to their large language models.
</p>
</div>
</div>

<div id="outline-container-orgf711b10" class="outline-2">
<h2 id="orgf711b10"><span class="section-number-2">3.</span> patterns in language</h2>
<div class="outline-text-2" id="text-3">
<p>
They argue, essentially, that llms create a new kind of object based
on "patterns" of language use in the training data. They explain that,
</p>
<blockquote>
<p>
"AI systems go well beyond preserving the content of individual works
by learning patterns in their whole training corpus and then using
those patterns to generate entirely novel media"
</p>
</blockquote>
<p>
They continue, explaining that,
</p>
<blockquote>
<p>
"by learning patterns from its training corpus, an AI system can
eventually generate media that shares some commonalities with works in
the corpus (in the same way that English sentences share some
commonalities with each other by sharing a common grammar and
vocabulary) but cannot be found in it." ("Comment", 9-10)
</p>
</blockquote>
<p>
What they refer to as patterns are statistical representations of
language, a numerical representation that encodes a words semantic
meaning to the langauge model.
</p>

<p>
Basically, inside every language model, exists a kind of dictionary.
This dictionary consists of individual words (every single word that
is present in the training corpus), and each word is appended not by a
definition in human language, but by a definition in computer
language, with numbers. These numbers which append each word,
represent probabilities between that word and <i>every single other word
in the corpus</i>. They are long, very long (and this is why language
models are caled "large") lists of probabilities. So, inside the
language model, each word is defined not by what it represents in
itself, but by its relation to every other word in the corpus.
</p>

<p>
<i>For example, the word "cat" will have a series of numbers that
closely resembles the series of numbers that append the word,
"kitten," and not as close to the numbers that represent "dog." Still,
the numbers for "cat" and "dog" will be much closer to each other than
the numbers that represent "flower," for example.</i>
</p>

<p>
Here is an example of the famous formula that introduced the concept
of the long list of numbers, known technically as "word vectors" to
the world.
</p>

<blockquote>
<p>
King - Man + Woman = Queen
</p>

<p>
Mikolov et al., "Distributed Representations of Words and Phrases and
their Compositionality", 2013.
</p>
</blockquote>

<p>
I always like to show this formula, because it illustrates exactly the
reason why we need more humanists (or more humanist training) involved
in engineering and computer science research.
</p>

<p>
The formula showcases power of word vectors: that they can be used
determine word meaning through calculations. In other words, if every
word is transformed into a numerical representation, we can do math
with language. We start with the vector for the word "King," that is,
a numerical representation of what "King" means in relation to every
other word. If, from the vector of "King," we subtract the vector of
"Man," and add that of "Woman," we will arrive at the vector for the
word "Queen."
</p>

<p>
Nevermind that the formula relies on gender role and identity as
symmetrically opposed and universally true, the idea is that word
meaning can be reliably computed.
</p>

<p>
And this is why, OpenAI argue, their product is "highly
transformative," because it turns words into numerical forms that
represent meaning as a kind of statistic.
</p>

<p>
But the thing that they do not mention, which they perhaps do not want to
admit, is that vectors are far from generalizations of language as a
fact of idea&#x2013; rather, vectors are specifically tied to the data on
which they were trained.
</p>

<p>
To demonstrate, I'm going to show a few examples of ML-generated text
based on two very different data sources.
</p>
</div>
</div>

<div id="outline-container-org0717b16" class="outline-2">
<h2 id="org0717b16"><span class="section-number-2">4.</span> close reading</h2>
<div class="outline-text-2" id="text-4">
<p>
I'm working on a project right now that uses Machine Learning to
study transphobia in text. I've been gathering datasets from
more conservative sources, like the Heritage Foundation, which is a
conservative think tank based in Washington DC.
</p>

<p>
SLIDE HERITAGE gender screenshot
www.heritage.org/gender?f[0]=content_type%3Acommentary   
</p>

<p>
From their website, I scraped all the articles that were organized
under the topic "gender", which you can see some of the headlines
here. 
</p>

<p>
I've also been gathering articles from more progressive sources, like
the ACLU, the American Civil Liberties Union, which is a group of
legal professionals and volunteers who advocate on behalf of civil
rights focued on immigrants, women, and trans people.
</p>

<p>
SLIDE ACLU trans screenshot
<a href="https://www.aclu.org/news/by-issue/transgender-rights">https://www.aclu.org/news/by-issue/transgender-rights</a> 
</p>

<p>
From both sources, I wanted to represent a contrast of perspectives on
gender and transgender. With these datasets, I then trained two very
small) large language models, using gpt-2 as the base model.
</p>

<p>
To the two resulting models, I fed a series of prompts, very simple
ones:
</p>

<p>
SLIDE prompts
</p>

<blockquote>
<p>
Masculinity is
</p>

<p>
Femininity is
</p>

<p>
Transgender is
</p>

<p>
Transgenderism is
</p>

<p>
Gender binary is
</p>

<p>
Man is
</p>

<p>
Woman is
</p>
</blockquote>

<p>
I'll show you some of the results here.
</p>

<p>
First, the obvious contrasts. For ACLU, terms associated with gender
"masculine" and "feminine" in particular, were characterized by joyous
and liberatory affects.
</p>

<blockquote>
<p>
Masculinity is a matter of love and celebration.
</p>

<p>
Masculinity is a space for hope and liberation for all.
</p>

<p>
Masculinity is not defined solely by the beauty of our bodies, but by
the beauty of our experiences.
</p>

<p>
Femininity is a celebration of beauty, feminine liberation, and femininity.
</p>

<p>
Femininity is a battle, a fight, fought for equal pay.
</p>

<p>
Femininity is our joy, our struggle, and our fight is our struggle.
</p>

<p>
Femininity is about allowing people to express themselves without government interference. 
</p>
</blockquote>

<p>
You can perhaps already see the tendency of llms (especially
pre-production ones) to repeat themselves. Which is a fascinating
quirk that I think comes from the fact that they are predictive
machines and get themselves into these predictive loops. 
</p>

<p>
By contrast, for the Heritage Foundation, these gender terms are
associated with stability and culture. 
</p>

<blockquote>
<p>
Masculinity is the cornerstone of Western civilization.
</p>

<p>
Masculinity is the fruit of patriarchy, and patriarchy is the heart
of conservatism.
</p>

<p>
Masculinity is defined by the ability to produce sperm, eggs, and live
children.
</p>

<p>
Femininity is an enduring American tradition.
</p>

<p>
Femininity is defined by means of the relationship between the sexes,
the ability to raise their children, the capacity to provide for their
own reproduction, the capacity to provide for their own children, the
ability to provide for their own.
</p>

<p>
Femininity is a cornerstone of our culture, and its impact on our
national and cultural achievements is far-reaching.
</p>
</blockquote>

<p>
"individualism" / "individualized"
</p>

<blockquote>
<p>
Femininity is defined by the term “queer of the material,” or ‘queer
of the material,” or ‘queer of the material,” especially in the form
of expressive individualism. (Heritage)
</p>

<p>
Women are the women of third-wave feminism, with the rise of
expressive individualism, and the feminist movement. (Heritage)
</p>

<p>
Transgender is a very individualized experience. (ACLU)
</p>

<p>
The gender binary is a very individualized form of identity. (ACLU)
</p>
</blockquote>

<p>
Subjective by heritage
</p>
<ul class="org-ul">
<li>you get the sense that these represent quotes or their paraphrases
from the trans-affirming side.</li>
<li>"subjective" associated with individual, psychology, fluid,
malleable, internal, transitory, and also incorrect and illogical.</li>
</ul>

<blockquote>
<p>
Masculinity is a subjective self-perception, not a universal
concept.
</p>

<p>
Femininity is a subjective, internal sense of self.
</p>

<p>
The gender binary is a subjective, psychological, and sometimes
physical construct that masquerates as a social construct.
</p>

<p>
The gender binary is a subjective, fluid system of questions that can
easily be answered by a simple yes or no answer.
</p>

<p>
The gender binary is a subjective, malleable, and often incorrect
idea.
</p>

<p>
The gender binary is a subjective, psychological, and biological
construct that is used to measure one’s sexual orientation or gender
identity (“segregated identity,” or whatever one might want to say it
is.
</p>

<p>
The gender binary is a subjective, internal, and often transitory
concept.
</p>

<p>
The gender binary is a subjective, grammatically incorrect and
illogical concept that conflates sex and gender identity.
</p>
</blockquote>

<p>
Reality by ACLU. Characterized by ambivalence, whether something is a
reality or is not a reality, there is a contrast. Could be due to the
paraphrasing of conservative views. 
</p>

<blockquote>
<p>
Masculinity is real and meaningful.
</p>

<p>
Transgenderism is a very real problem.
</p>

<p>
Transgenderism is a false ideology that is not real and that is
opposed by the very people who seek to deny that freedom and equality
for all.
</p>

<p>
The gender binary is not real, it is real, and it is real.
</p>

<p>
The gender binary is not a reality invented by cisgender people.
</p>

<p>
The gender binary is a binary without any real physical and emotional
freedom.
</p>

<p>
The gender binary is not a binary, it is a reality within us.
</p>

<p>
The gender binary is not a reality that we cling to most as vestiges
of sexism and patriarchy.
</p>

<p>
The gender binary is not real, it operates on a very different level
of social isolation.
</p>

<p>
The gender binary is not an accepted reality, but one that is accepted
by a wide swath of people.
</p>
</blockquote>

<p>
We are speaking in terms of patterns: here we see two distinct
patterns around the concept of subjectivity and reality: one
perspective (the conservative) discusses gender identity as a
subjective, internal thing toward a goal of discounting it. Another
side (the progressive) defines reality through ambivalance, through
distinctions. 
</p>

<p>
And interestingly it reveals something that fundamentally contradicts
how companies like OpenAI try to characterize llms as "idealizations"
or "facts" of language use. 
</p>

<p>
Yes, the language here reflects generalizations from patterns, but
patterns have been filtered through other patterns.
</p>

<p>
There is a layering here, of the heritage and aclu perspectives: they
are themselves layering other perspectives beneath them. They are
quoting and paraphrasing from the opposite point of view.
</p>

<p>
Here, from ACLU, I cannot tell if this is pro or anti-trans:
</p>

<blockquote>
<p>

</p>

<p>
The gender binary is not a binary, it is a reality within us.
</p>
</blockquote>

<p>
So there is no "fact" or "idealized" level of language here, but
layers of distinct expressions. 
</p>
</div>
</div>
</div>
<div id="postamble" class="status">
<p class="author">Author: fcalado</p>
<p class="date">Created: 2025-07-07 Mon 12:18</p>
<p class="validation"><a href="https://validator.w3.org/check?uri=referer">Validate</a></p>
</div>
</body>
</html>
