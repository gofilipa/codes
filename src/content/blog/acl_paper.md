---
title: Some Myths About Bias
description: 'Description of paper submission to ACL, and thinking
about what we should do with gender bias'
pubDate: 'May 1, 2025'
heroImage: '/codes/myths.png'
---

I recently submitted a paper, called "[Some Myths About
Bias](https://github.com/gofilipa/anti-trans-legislation/blob/main/papers/some_myths/acl/submission/final.pdf),"
to the Association for Computational Linguistics 2025 conference
(ACL).

The paper, which I have been working on since the new year, is about
binaries, and how a form of what I call "binary thinking" pervades
research about gender bias in NLP. The idea is that the binary model
goes beyond the realm of gender (beyond the binary of male/female, in
other words) and into a structure of thought that simplifies the ways
we conceptualize gender bias.

In the paper, I outline how this form of "binary thinking" inspires
two myths about bias: (1) that bias is categorical, and (2) that bias
is zero-sum. In other words, that bias can be detected as a yes/no
value, which collapses the type and effect of bias into a single
indicator of harm; and that equality exists between terms and their
connotations, which overlooks the ways masculine or feminine
connotations function descriptively, are not (always) denigrating.

These myths, I argue, attempt to shepherd bias into schemas that
fundamentally misunderstand the way that bias works. The effect is
that techniques for studying and mitigating gender bias often miss the
mark.

This paper is a necessary step for me to do the thing I want to do
next: create a dataset to explore gender expressions for the purpose
of studying gender bias as a physical phenomenon. Here I'm following
an argument from Kadj Amin's essay, "[We are all
nonbinary](https://wgss.emory.edu/documents/AminNonbinary.pdf)" about
conceptualizing gender in ways that make visible those who are most
marginalized by gender norms. Amin suggests that gender be
conceptualized through physical aspects, such as behavior and
expression, rather than through identification, which is internal. The
idea is that marking gender as an external, outward-facing phenomenon
will make visible those who occupy historically marginal gender
expressions, especially those that are feminized.

To that end, I am considering what kinds of datasets I should compile.
One I've been working on for a while is the [anti-trans
legislation](https://github.com/gofilipa/anti-trans-legislation)
dataset, which is really about marking up transphobia. I'm wondering
if this is the right direction to go in, because the markup in this
case isn't just about gender expression, but also fear of gender
non-conformity. And fear is not a physical phenomenon. (Ironically, I
argue the opposite in my dissertation chapter on fear and desire).

(On the subject of my dissertation, which I'm in the process of
re-thinking into a book---I'm also wondering about markup for datasets
and markup for TEI. The markup for TEI reveals the gaps in the
evidence, which indicates power structures operating under the hood
(in my case, privilege of whiteness in theorizing sexuality). But the
markup for the datasets, if they pay attention to physicality, can
actually work to reveal something useful or new about gender. Though
not to pin it down.)

Here, I remind myself the difference between my project and others
working in the area of gender bias in NLP: I am not trying to get rid
of bias. What I want is to find new ways and forms for studying it.

So I guess the biggest myth about bias, which is not explicit in the
paper, but which drives all of its thinking, is that we can eliminate
it in the first place.

